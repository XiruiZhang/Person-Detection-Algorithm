{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fi7Y0r3NpJud","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608514645798,"user_tz":300,"elapsed":2665,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"4ac46329-a438-49c8-9ff0-87e79e4f65bd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# path for google drive\n","path = '/content/drive/My Drive/ECSE415/FinalProject/'\n","frame_path = '/content/drive/My Drive/ECSE415/FinalProject/frames/'\n","positive_path = '/content/drive/My Drive/ECSE415/FinalProject/positive/'\n","negative_path = '/content/drive/My Drive/ECSE415/FinalProject/negative/'\n","person_path = '/content/drive/My Drive/ECSE415/FinalProject/person/'\n","positive_test = '/content/drive/My Drive/ECSE415/FinalProject/positive_test/'\n","negative_test = '/content/drive/My Drive/ECSE415/FinalProject/negative_test/'"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QP4RgUQwpYSL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608514645796,"user_tz":300,"elapsed":4917,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"23d99637-9996-4773-876e-74fd1375a85b"},"source":["# install dependencies: \n","!pip install pyyaml==5.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","!pip install --upgrade imutils\n","# opencv is pre-installed on colab"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.6/dist-packages (5.1)\n","1.7.0+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n","Requirement already up-to-date: imutils in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"09hFtoYHpiLL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608514648148,"user_tz":300,"elapsed":5007,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"be5c35d0-0458-424f-9c6e-ccac050ac542"},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","import torch\n","assert torch.__version__.startswith(\"1.7\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","Requirement already satisfied: detectron2 in /usr/local/lib/python3.6/dist-packages (0.3+cu101)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.0.2)\n","Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.1.2.post20201218)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.4.0)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (8.0.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (50.3.2)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\n","Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (0.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2) (1.19.4)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot->detectron2) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.3.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.10.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.17.2)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.12.4)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.36.2)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.32.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.15.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2) (2.0.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (3.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6h60pBrqqxbX","executionInfo":{"status":"ok","timestamp":1608514648270,"user_tz":300,"elapsed":5126,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","from skimage.feature import hog\n","\n","import time\n","import random as rg\n","import math\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","import csv"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MLFqNaZDktEg"},"source":["# Image extraction from folders and creating image set"]},{"cell_type":"code","metadata":{"id":"q0KTubcuH3Hu","executionInfo":{"status":"ok","timestamp":1608514648272,"user_tz":300,"elapsed":5125,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def CreateTrainSet(positive_path, negative_path, IMAGE_WIDTH, IMAGE_HEIGHT, Positive_Images=1200):\r\n","  # getting all file names from positive path\r\n","  positives = os.listdir(positive_path)\r\n","  positive_files = [os.path.join(positive_path, file_name) for file_name in positives if file_name.endswith('.jpg')]\r\n","  positive_files.sort()\r\n","\r\n","  # getting all file names from negative path\r\n","  negatives = os.listdir(negative_path) \r\n","  negative_files = [os.path.join(negative_path, file_name) for file_name in negatives if file_name.endswith('.jpg')]\r\n","  negative_files.sort()\r\n","\r\n","  # creating train label np array for pos=0 and neg=1\r\n","  pos_labels = np.zeros(Positive_Images)\r\n","  neg_labels = np.ones(len(negative_files))\r\n","  train_labels = np.concatenate((pos_labels, neg_labels), axis=0).astype(int)\r\n","  \r\n","  # add positive images to train_image np array\r\n","  pos_images = np.zeros((Positive_Images, IMAGE_HEIGHT, IMAGE_WIDTH))\r\n","  for filename in positive_files[0: Positive_Images]:\r\n","    img = cv2.imread(filename, 0)\r\n","    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\r\n","    pos_images[positive_files.index(filename)] = img\r\n","  \r\n","  # add negative images to train_image np array\r\n","  neg_images = np.zeros((len(negative_files), IMAGE_HEIGHT, IMAGE_WIDTH))\r\n","  for filename in negative_files:\r\n","    img = cv2.imread(filename, 0)\r\n","    img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\r\n","    neg_images[negative_files.index(filename)] = img\r\n","  \r\n","  train_images = np.zeros((len(positive_files)+len(negative_files), IMAGE_HEIGHT, IMAGE_WIDTH))\r\n","  train_images = np.concatenate((pos_images, neg_images), axis=0).astype(int)\r\n","  return train_images, train_labels"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Cq-7-nJLgTi","executionInfo":{"status":"ok","timestamp":1608514903653,"user_tz":300,"elapsed":260501,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"1c227225-2ed7-4265-e8df-b57705c56151"},"source":["Positive_Images = 1200\r\n","print(f\"Path exists: {os.path.isdir(positive_path) and os.path.isdir(negative_path)}\")\r\n","IMAGE_WIDTH = 64\r\n","IMAGE_HEIGHT = 128\r\n","R_train_images, train_labels = CreateTrainSet(positive_path, negative_path, IMAGE_WIDTH, IMAGE_HEIGHT, Positive_Images)\r\n","\r\n","print(\"train_images: \", R_train_images.shape)\r\n","print(\"train_labels: \", train_labels.shape)\r\n","print(R_train_images[0])\r\n","print(train_labels[0])\r\n","print(R_train_images[-1])\r\n","print(train_labels[-1])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Path exists: True\n","train_images:  (1480, 128, 64)\n","train_labels:  (1480,)\n","[[196 197 201 ... 124 119 117]\n"," [195 197 200 ... 125 118 115]\n"," [195 196 200 ... 126 116 111]\n"," ...\n"," [181 181 181 ... 182 181 181]\n"," [178 178 177 ... 184 184 184]\n"," [176 176 175 ... 186 186 186]]\n","0\n","[[198 198 197 ... 123 113 106]\n"," [196 196 196 ... 121 115 113]\n"," [194 194 194 ... 121 123 128]\n"," ...\n"," [247 247 246 ... 246 245 245]\n"," [250 250 248 ... 244 244 244]\n"," [247 247 246 ... 246 247 247]]\n","1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PxZPoviLkymJ"},"source":["# Getting Hog features and creating training feature set"]},{"cell_type":"code","metadata":{"id":"dnz6mNLNHw0J","executionInfo":{"status":"ok","timestamp":1608514903658,"user_tz":300,"elapsed":260504,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["# returns HoG features, and orderd features\r\n","def HoG_features(images):\r\n","    cell_size = (8,8)\r\n","    block_size = (4,4)\r\n","    nbins = 4\r\n","\r\n","    # all images have same shape\r\n","    img_size = images[0].shape\r\n","\r\n","    # creating HoG object\r\n","    hog = cv2.HOGDescriptor(_winSize=(img_size[1] // cell_size[1] * cell_size[1],\r\n","                                    img_size[0] // cell_size[0] * cell_size[0]),\r\n","                            _blockSize=(block_size[1] * cell_size[1],\r\n","                                        block_size[0] * cell_size[0]),\r\n","                            _blockStride=(cell_size[1], cell_size[0]),\r\n","                            _cellSize=(cell_size[1], cell_size[0]),\r\n","                            _nbins=nbins)\r\n","\r\n","    features = []\r\n","    for i in range(images.shape[0]):\r\n","        \r\n","        # Compute HoG features\r\n","        features.append(hog.compute((images[i]).astype(np.uint8)).reshape(1, -1))\r\n","    \r\n","    # Stack arrays in sequence vertically \r\n","    features = np.vstack(features)\r\n","   \r\n","    return features"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGhKFPGDH-IU","executionInfo":{"status":"ok","timestamp":1608514904538,"user_tz":300,"elapsed":261378,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"1dd28249-c06d-4676-dd0e-57461641d03b"},"source":["# getting HoG features\r\n","train_features = HoG_features(R_train_images)\r\n","print(\"trained_features_reshaped: \", train_features.shape)\r\n","print(\"trained_features_reshaped[0]: \", train_features[0])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["trained_features_reshaped:  (1480, 4160)\n","trained_features_reshaped[0]:  [0.03915166 0.0065741  0.00676362 ... 0.0232183  0.02239115 0.00087363]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LA2ScFHMkmBO"},"source":["# Non-linear SVM Classifier"]},{"cell_type":"code","metadata":{"id":"vrYkGmWBZoyj","executionInfo":{"status":"ok","timestamp":1608514904543,"user_tz":300,"elapsed":261381,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def NonLinear_SVM(train_features, train_labels, gamma, C, random_state=None):\r\n","    # creating non-linear svc object, RBF kernel is default\r\n","    clf = svm.SVC(C=C, gamma=gamma, random_state=random_state)\r\n","\r\n","    # fit and predict\r\n","    clf.fit(train_features, train_labels)\r\n","    return clf\r\n","\r\n","def predict(clf, test_features, test_labels):\r\n","    predict = clf.predict(test_features)\r\n","    \r\n","    # using accruacy score from metrics lib and multiply 100 to get precentage\r\n","    accuracy = accuracy_score(test_labels, predict)*100\r\n","    return accuracy"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CY1-SzjekBTY"},"source":["# 1 Fold Validation"]},{"cell_type":"code","metadata":{"id":"WD7l7YOMZfW8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608514904546,"user_tz":300,"elapsed":261379,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"f7bf2bbf-9a12-48a2-86fd-d383290d299f"},"source":["k_fold = 5\r\n","pos_count = Positive_Images\r\n","neg_count = 280\r\n","pos_train_split = int(pos_count*4/k_fold)\r\n","neg_train_split = int(pos_count+neg_count*4/k_fold)\r\n","\r\n","print(f\"train_size: {pos_train_split+neg_train_split-pos_count}\")\r\n","print(f\"test_size: {pos_count-pos_train_split+neg_count-neg_train_split+pos_count}\")\r\n","\r\n","# splitting all pos and neg into 4/5 for train and 1/5 split for test\r\n","train_features_split = np.concatenate((train_features[: pos_train_split],  train_features[pos_count: neg_train_split]), axis=0)\r\n","train_labels_split = np.concatenate((train_labels[: pos_train_split], train_labels[pos_count: neg_train_split]), axis=0)\r\n","\r\n","val_features_split = np.concatenate((train_features[pos_train_split:pos_count],  train_features[neg_train_split:]), axis=0)\r\n","val_labels_split = np.concatenate((train_labels[pos_train_split:pos_count],  train_labels[neg_train_split:]), axis=0)\r\n","\r\n","print(f\"train_split: {train_features_split.shape} and {train_labels_split.shape}\")\r\n","print(f\"val_split: {val_features_split.shape} and {val_labels_split.shape}\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["train_size: 1184\n","test_size: 296\n","train_split: (1184, 4160) and (1184,)\n","val_split: (296, 4160) and (296,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5lVqcAVryHtu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608514950943,"user_tz":300,"elapsed":307774,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"8f92a668-f108-4c9b-f06b-4e41eb15a5d2"},"source":["MIN_ACCURACY = 50\r\n","GammaList = ['auto', 'scale']\r\n","C_List = [0.01, 0.1, 1, 10, 100, 1000]\r\n","Best_SVM = {\"gamma\":None, \"C\":None, \"accuracy\":0}\r\n","for gamma in GammaList:\r\n","    for C in C_List:\r\n","        clf = NonLinear_SVM(train_features_split, train_labels_split, gamma, C)\r\n","        accuracy = predict(clf, val_features_split, val_labels_split)\r\n","        if round(accuracy, 2) > MIN_ACCURACY:\r\n","            print(f\"Gamma: {gamma}, C: {C},  Accuracy: {round(accuracy, 2)}%\")\r\n","        if round(accuracy, 2) > Best_SVM[\"accuracy\"]:\r\n","            Best_SVM[\"gamma\"] = gamma\r\n","            Best_SVM[\"C\"] = C\r\n","            Best_SVM[\"accuracy\"] = round(accuracy, 2)\r\n","print(\"Best parameters: \", Best_SVM)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Gamma: auto, C: 0.01,  Accuracy: 81.08%\n","Gamma: auto, C: 0.1,  Accuracy: 81.08%\n","Gamma: auto, C: 1,  Accuracy: 81.08%\n","Gamma: auto, C: 10,  Accuracy: 87.16%\n","Gamma: auto, C: 100,  Accuracy: 95.27%\n","Gamma: auto, C: 1000,  Accuracy: 95.95%\n","Gamma: scale, C: 0.01,  Accuracy: 81.08%\n","Gamma: scale, C: 0.1,  Accuracy: 83.45%\n","Gamma: scale, C: 1,  Accuracy: 95.95%\n","Gamma: scale, C: 10,  Accuracy: 96.62%\n","Gamma: scale, C: 100,  Accuracy: 96.62%\n","Gamma: scale, C: 1000,  Accuracy: 96.62%\n","Best parameters:  {'gamma': 'scale', 'C': 10, 'accuracy': 96.62}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6w2C_y9_j5oD"},"source":["# 5 Fold Cross Validation"]},{"cell_type":"code","metadata":{"id":"N_QVxdeNiwvZ","executionInfo":{"status":"ok","timestamp":1608514950946,"user_tz":300,"elapsed":307774,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def k_fold_SVC(train_features, train_labels, train_index, val_index, k_folds):\r\n","    total_accuracy = 0\r\n","    for i in range(k_folds):\r\n","        x_train, x_val = train_features[train_index], train_features[val_index]\r\n","        y_train, y_val = train_labels[train_index], train_labels[val_index]\r\n","        clf = NonLinear_SVM(x_train, y_train, gamma, C)\r\n","        total_accuracy += predict(clf, x_val, y_val)\r\n","    avg_accuracy = total_accuracy/k_folds\r\n","    return avg_accuracy"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_twjHV5j2pB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608516154377,"user_tz":300,"elapsed":1511203,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"7ba0aa3b-ea0f-419d-a387-8198e8e462af"},"source":["# 5 fold cross validation dataset\r\n","k_folds = 5\r\n","kf = KFold(n_splits=k_folds, shuffle=True)\r\n","kf.get_n_splits(train_features)\r\n","\r\n","MIN_ACCURACY = 50\r\n","GammaList = ['auto', 'scale']\r\n","C_List = [0.01, 0.1, 1, 10, 100, 1000]\r\n","Best_SVM = {\"gamma\":None, \"C\":None, \"accuracy\":0}\r\n","for gamma in GammaList:\r\n","    for C in C_List:\r\n","        start_time = time.time()\r\n","        for train_index, val_index in kf.split(train_features):\r\n","            accuracy = k_fold_SVC(train_features, train_labels, train_index, val_index, 5)\r\n","        time_taken = (time.time() - (start_time))/k_folds\r\n","        if round(accuracy, 2) > MIN_ACCURACY:\r\n","            print(f\"Gamma: {gamma}, C: {C},  Accuracy: {round(accuracy, 2)}%, time taken to train/test: {round(time_taken, 2)}\")\r\n","        if round(accuracy, 2) > Best_SVM[\"accuracy\"]:\r\n","            Best_SVM[\"gamma\"] = gamma\r\n","            Best_SVM[\"C\"] = C\r\n","            Best_SVM[\"accuracy\"] = round(accuracy, 2)\r\n","print(\"Best parameters: \", Best_SVM)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Gamma: auto, C: 0.01,  Accuracy: 81.42%, time taken to train/test: 20.56\n","Gamma: auto, C: 0.1,  Accuracy: 81.76%, time taken to train/test: 21.3\n","Gamma: auto, C: 1,  Accuracy: 84.46%, time taken to train/test: 22.3\n","Gamma: auto, C: 10,  Accuracy: 87.5%, time taken to train/test: 21.92\n","Gamma: auto, C: 100,  Accuracy: 95.27%, time taken to train/test: 15.74\n","Gamma: auto, C: 1000,  Accuracy: 96.96%, time taken to train/test: 13.35\n","Gamma: scale, C: 0.01,  Accuracy: 83.45%, time taken to train/test: 23.37\n","Gamma: scale, C: 0.1,  Accuracy: 84.12%, time taken to train/test: 23.85\n","Gamma: scale, C: 1,  Accuracy: 96.28%, time taken to train/test: 19.13\n","Gamma: scale, C: 10,  Accuracy: 98.65%, time taken to train/test: 19.26\n","Gamma: scale, C: 100,  Accuracy: 96.96%, time taken to train/test: 19.64\n","Gamma: scale, C: 1000,  Accuracy: 97.3%, time taken to train/test: 20.25\n","Best parameters:  {'gamma': 'scale', 'C': 10, 'accuracy': 98.65}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bk4TeIzhkGev"},"source":["# Using Optimal Paramaeters for SVM Classifier"]},{"cell_type":"code","metadata":{"id":"l7y5TnnobXzi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608516158219,"user_tz":300,"elapsed":1515040,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"5b3fb66e-0207-4c11-fbf7-246956e3dbe3"},"source":["# Optimal SVM Classifer\n","gamma = \"scale\"\n","C = 10\n","Optimal_Clf = NonLinear_SVM(train_features_split, train_labels_split, gamma, C)\n","accuracy = predict(clf, val_features_split, val_labels_split)\n","print(f\"Gamma: {gamma}, C: {C},  Accuracy: {round(accuracy, 2)}%\")"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Gamma: scale, C: 10,  Accuracy: 96.62%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ERj3pKe4lGWO"},"source":["# Comparison with detectron"]},{"cell_type":"code","metadata":{"id":"FRn6q0qllODn","executionInfo":{"status":"ok","timestamp":1608516616979,"user_tz":300,"elapsed":1973797,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def load_images(image_path):\r\n","  files = os.listdir(frame_path) \r\n","  files_name = [file_name for file_name in files if file_name.endswith('.jpg')]\r\n","  files_name.sort()\r\n","  frames = []\r\n","\r\n","  #read the first 100 images\r\n","  for i, file_name in enumerate(files_name):\r\n","    frame = cv2.imread(image_path + file_name)\r\n","    frames.append(frame)\r\n","\r\n","  frames = np.array(frames)\r\n","  return frames\r\n","seq_images = load_images(frame_path)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqb3c5HynmW4","executionInfo":{"status":"ok","timestamp":1608516635294,"user_tz":300,"elapsed":1992108,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"5eb8eb86-edc0-4c7c-8775-485758b52fc8"},"source":["cfg = get_cfg()\r\n","# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\r\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\r\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\r\n","# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\r\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\r\n","predictor = DefaultPredictor(cfg)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["model_final_280758.pkl: 167MB [00:06, 24.0MB/s]                           \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iynu6xMlnnuc","executionInfo":{"status":"ok","timestamp":1608516635447,"user_tz":300,"elapsed":1992258,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["# crop positive samples\r\n","def crop_objects(img, outputs, image_index, writer):\r\n","  classes = outputs[\"instances\"].pred_classes\r\n","  boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\r\n","  #create dictionary to hold count of objects for image name\r\n","  index = -1\r\n","  count = 0\r\n","  print()\r\n","  test_images = []\r\n","  test_labels = []\r\n","  for class_index in classes:\r\n","    # get count of class for part of image name\r\n","    # class_index = int(classes[i])\r\n","    if class_index == 0:\r\n","      # get box coords\r\n","      box = boxes[index]\r\n","      # print(box)\r\n","      xmin, ymin, xmax, ymax = box\r\n","      # crop detection from image (take an additional 5 pixels around all edges)\r\n","      cropped_img = img[int(ymin):int(ymax), int(xmin):int(xmax)]\r\n","\r\n","      test_images.append(cropped_img)\r\n","      test_labels.append(0)\r\n","      count+=1\r\n","  writer.writerow([image_index+1, count])\r\n","  return writer, test_images, test_labels"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTywjdNcwrC5","executionInfo":{"status":"ok","timestamp":1608516635448,"user_tz":300,"elapsed":1992256,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["# returns an array of resized images and converts to grayscale\r\n","def ResizeImages(images, IMAGE_WIDTH, IMAGE_HEIGHT):\r\n","    ResizedImages = np.zeros((len(images), IMAGE_HEIGHT, IMAGE_WIDTH))\r\n","    for i in range(len(images)):\r\n","      img = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\r\n","      ResizedImages[i] = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\r\n","    return ResizedImages"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"I52yp6vu0cgZ","executionInfo":{"status":"ok","timestamp":1608516635449,"user_tz":300,"elapsed":1992254,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def comparative_acc(Optimal_Clf, test_images, test_labels):\r\n","    # resize and grayscale for HoG\r\n","    R_test_images = ResizeImages(test_images, IMAGE_WIDTH, IMAGE_HEIGHT)\r\n","    # print(\"R_train_images: \", R_train_images.shape)\r\n","\r\n","    # create HoG test features\r\n","    test_features = HoG_features(R_test_images)\r\n","    # print(\"trained_features_reshaped: \", test_features.shape)\r\n","    # print(\"trained_features_reshaped[0]: \", test_features[0])\r\n","\r\n","    # accuracy\r\n","    accuracy = predict(Optimal_Clf, test_features, test_labels)\r\n","    # print(f\"Gamma: {gamma}, C: {C},  Accuracy: {round(accuracy, 2)}%\")\r\n","    return accuracy"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CRInrNJmnqhv","executionInfo":{"status":"ok","timestamp":1608517027101,"user_tz":300,"elapsed":2383892,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"45ac8783-e8ce-4210-bfa4-76b69790427e"},"source":["cfile = open(path + 'detectron_count.csv', 'w+', newline='')\r\n","accfile = open(path + 'accuracy_comparison.csv', 'w+', newline='')\r\n","writer = csv.writer(cfile)\r\n","writer.writerow([\"id\", \"Count\"])\r\n","acc_writer = csv.writer(accfile)\r\n","acc_writer.writerow([\"id\", \"accuracy\"])\r\n","\r\n","# getting HoG features\r\n","IMAGE_WIDTH = 64    # same as train image\r\n","IMAGE_HEIGHT = 128\r\n","\r\n","# use optimal parameter for model\r\n","gamma = \"scale\"\r\n","C = 10\r\n","\r\n","test_img_set = []\r\n","for image_index in range(len(seq_images)):\r\n","  try:\r\n","    outputs = predictor(seq_images[image_index])\r\n","    writer, test_images, test_labels = crop_objects(seq_images[image_index], outputs, image_index, writer)\r\n","    accuracy = comparative_acc(Optimal_Clf, test_images, test_labels)\r\n","    acc_writer.writerow([image_index+1, accuracy])\r\n","  except Exception as e:\r\n","    print(str(e))\r\n","\r\n","cfile.close\r\n","accfile.close\r\n","\r\n","v = Visualizer(seq_images[0][:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)\r\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n","cv2_imshow(out.get_image()[:, :, ::-1])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  filter_inds = filter_mask.nonzero()\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mSaves\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mimage\u001b[0m \u001b[0munder\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpreinit\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;31m# --------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m \u001b[0;31m# Helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0m_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/JpegImagePlugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTiffImagePlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_binary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mi16be\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mi16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mImageFileDirectory_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \"\"\"This class represents a TIFF tag directory.  To speed things up, we\n\u001b[1;32m    404\u001b[0m     \u001b[0mdon\u001b[0m\u001b[0;34m't decode tags unless they'\u001b[0m\u001b[0mre\u001b[0m \u001b[0masked\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py\u001b[0m in \u001b[0;36mImageFileDirectory_v2\u001b[0;34m()\u001b[0m\n\u001b[1;32m    666\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mTiffTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLOAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mTiffTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOUBLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"double\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mTiffTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIFD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m             ],\n\u001b[1;32m    670\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: module 'PIL.TiffTags' has no attribute 'IFD'"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=640x480 at 0x7FA948C43A90>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"IXYetFblT9_2","colab":{"base_uri":"https://localhost:8080/","height":135},"executionInfo":{"status":"error","timestamp":1608517027495,"user_tz":300,"elapsed":2384284,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}},"outputId":"d8f8565c-cfcc-4032-dbfe-135981a7acb1"},"source":["import imutils\r\n","def pyramid(image, scale=1.5, minSize=(30, 30)):\r\n","\t# yield the original image\r\n","\tyield image\r\n","\t# keep looping over the pyramid\r\n","\twhile True:\r\n","\t\t# compute the new dimensions of the image and resize it\r\n","\t\tw = int(image.shape[1] / scale)\r\n","\t\timage = imutils.resize(image, width=w)\r\n","\t\t# if the resized image does not meet the supplied minimum\r\n","\t\t# size, then stop constructing the pyramid\r\n","\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\r\n","\t\t\tbreak\r\n","\t\t# yield the next image in the pyramid\r\n","\t\tyield image\r\n","\r\n","def sliding_window(image, stepSize, windowSize):\r\n","\t# slide a window across the image\r\n","\tfor y in range(0, image.shape[0], stepSize):\r\n","\t\tfor x in range(0, image.shape[1], stepSize):\r\n","\t\t\t# yield the current window\r\n","\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\r\n","\r\n","def detectron_detect(img):\r\n","  frame = np.array(img)\r\n","  outputs = predictor(frame)\r\n","  v = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)\r\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\r\n","  cv2_imshow(out.get_image()[:, :, ::-1])\r\n","  classes = outputs[\"instances\"].pred_classes\r\n","  boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\r\n","  #create dictionary to hold count of objects for image name\r\n","  index = -1\r\n","  count = 0\r\n","  for class_index in classes:\r\n","    index+=1\r\n","    if class_index == 0:\r\n","      # get box coords\r\n","      box = boxes[index]\r\n","  return class_index, box\r\n","\r\n","(winW, winH) = (64, 128)\r\n","def window_predict(clf, image):\r\n","  person_count = 0\r\n","  # loop over the image pyramid\r\n","  for resized in pyramid(image, scale=1.5):\r\n","    # loop over the sliding window for each layer of the pyramid\r\n","    for (x, y, window) in sliding_window(resized, stepSize=32, windowSize=(winW, winH)):\r\n","      # if the window does not meet our desired window size, ignore it\r\n","      if window.shape[0] != winH or window.shape[1] != winW:\r\n","        # detectron predict\r\n","        det_label, det_box = detectron_detect(window))\r\n","        \r\n","        # svm prediction\r\n","        # test feature: window\r\n","        SVM_prediction = clf.predict(window)\r\n","        # both predict true\r\n","        if SVM_prediction == 1 and det_label == 0:\r\n","          person_count += 1\r\n","          SumIOU += bb_intersection_over_union(window, det_box)\r\n","        # SVM predicts true || False Positive\r\n","        elif SVM_prediction == 1:\r\n","          SumIOU += 0\r\n","          person_count += 1\r\n","        # detectron predicts true || False Negative\r\n","        elif det_label == 0:\r\n","          SumIOU += 0\r\n","          person_count += 1\r\n","\r\n","        # since we do not have a classifier, we'll just draw the window\r\n","        clone = resized.copy()\r\n","        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\r\n","        # cv2_imshow(\"Window\", clone)\r\n","        # cv2.waitKey(1)\r\n","        # time.sleep(0.025)\r\n","  AvgIOU = SumIOU / person_count \r\n","  return AvgIOU"],"execution_count":30,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-5cb8893f8207>\"\u001b[0;36m, line \u001b[0;32m52\u001b[0m\n\u001b[0;31m    det_label, det_box = detectron_detect(window))\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"3FWasZ_8NQkH","executionInfo":{"status":"aborted","timestamp":1608517027321,"user_tz":300,"elapsed":2384108,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def bb_intersection_over_union(BoxA, BoxB):\r\n","  A_xmin, A_ymin, A_xmax, A_ymax = BoxA\r\n","  B_xmin, B_ymin, B_xmax, B_ymax = BoxB\r\n","\r\n","  # determine the (x, y)-coordinates of the intersection rectangle\r\n","  xA = max(A_xmin, B_xmin)\r\n","  yA = max(A_ymin, B_ymin)\r\n","  xB = min(A_xmax, B_xmax)\r\n","  yB = min(A_ymax, B_ymax)\r\n","  # compute the area of intersection rectangle\r\n","  interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\r\n","  # compute the area of both the prediction and ground-truth\r\n","  # rectangles\r\n","  boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\r\n","  boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\r\n","  # compute the intersection over union by taking the intersection\r\n","  # area and dividing it by the sum of prediction + ground-truth\r\n","  # areas - the interesection area\r\n","  iou = interArea / float(boxAArea + boxBArea - interArea)\r\n","  # return the intersection over union value\r\n","  return iou"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M61nVVdGq4d3","executionInfo":{"status":"aborted","timestamp":1608517027323,"user_tz":300,"elapsed":2384107,"user":{"displayName":"Ismail Faruk","photoUrl":"","userId":"13200108287157530981"}}},"source":["def LBP(images, radius):\n","    P = 8 * radius\n","    R = radius\n","    features = []\n","    eps = 1e-7\n","    for img in images:\n","        lbp = feature.local_binary_pattern(img, P, R)\n","        (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, P + 3),range=(0, P + 2))\n","        # normalize the histogram\n","        hist = hist.astype(\"float\")\n","        hist /= (hist.sum() + eps)\n","        if np.isnan(hist.any()):\n","            print(\"nan\")\n","        \n","        features.append(hist)\n","    features=np.array(features)\n","    return features"],"execution_count":null,"outputs":[]}]}